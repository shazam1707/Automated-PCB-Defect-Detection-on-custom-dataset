{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13080528,"sourceType":"datasetVersion","datasetId":8284633}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DEPENDENCIES","metadata":{}},{"cell_type":"code","source":"import IPython.display as display\n!pip uninstall -y requests\n\n!pip install -U urllib3 requests\ndisplay.clear_output()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -y torch torchvision\n!pip install torch==2.0.0 torchvision==0.15.1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U openmim\n!pip install \"mmengine>=0.7.1,<1.0.0\" \\\n \"mmcv>=2.0.0rc4,<2.1.0\" \\\n \"mmdet>=3.0.0,<3.1.0\" \\\n -f https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html \\\n--trusted-host download.openmmlab.com","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/open-mmlab/mmyolo.git\n%cd mmyolo\n\n!pip install -r requirements/mminstall.txt\n# Install albumentations\n!pip install -r requirements/albu.txt\n# Install MMYOLO\n!pip install -v -e .\n# \"-v\" means verbose, or more output\n# \"-e\" means installing a project in editable mode,\n# thus any local modifications made to the code will take effect without reinstallation.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import the dataset to MMYOLO","metadata":{}},{"cell_type":"code","source":"#copying the dataset to mmyolo directory\n\nimport shutil\nimport os\n\n# Source directory to copy\nsrc_dir = '/kaggle/input/loserspcb-v2/combined_trialv4_updated'\n\n# Destination directory where the source directory will be copied\ndst_dir = '/kaggle/working/mmyolo/datasets'\n\n# Remove destination directory if it exists\nif os.path.exists(dst_dir):\n    shutil.rmtree(dst_dir)\n\n# Copy the entire directory tree\nshutil.copytree(src_dir, dst_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modifying the base YOLOv6-s cofig","metadata":{}},{"cell_type":"code","source":"\nconfig_base_yolov6= \"\"\"\n_base_ = ['../_base_/default_runtime.py']\n\n# ========================Frequently modified parameters======================\n# -----data related-----\ndata_root = './datasets/'  # Root path of data\n# Path of train annotation file\ntrain_ann_file = 'train.json'\ntrain_data_prefix = 'train/'  # Prefix of train image path\n# Path of val annotation file\nval_ann_file = 'val.json'\nval_data_prefix = 'val/'  # Prefix of val image path\n\nnum_classes = 5  # Number of classes for classification\n\nmetainfo = {\n    'classes': ('MP','OC','SC','SP','SPC')\n    }\n\ntrain_batch_size_per_gpu = 4\ntrain_num_workers = 1\npersistent_workers = True\n\n# -----train val related-----\n# Base learning rate for optim_wrapper\nbase_lr = 0.01\nmax_epochs = 50  # Maximum training epochs\n\n\n# ======================= Possible modified parameters =======================\n# -----data related-----\nimg_scale = (1024, 1024)  # width, height\n# Dataset type, this will be used to define the dataset\ndataset_type = 'YOLOv5CocoDataset'\n# Batch size of a single GPU during validation\nval_batch_size_per_gpu = 2\n# Worker to pre-fetch data for each single GPU during validation\nval_num_workers = 1\n\n# Config of batch shapes. Only on val.\n# It means not used if batch_shapes_cfg is None.\nbatch_shapes_cfg = dict(\n    type='BatchShapePolicy',\n    batch_size=val_batch_size_per_gpu,\n    img_size=img_scale[0],\n    size_divisor=32,\n    extra_pad_ratio=0.5)\n\n# -----model related-----\n# The scaling factor that controls the depth of the network structure\ndeepen_factor = 0.33\n# The scaling factor that controls the width of the network structure\nwiden_factor = 0.5\n\n# -----train val related-----\naffine_scale = 0.5  # YOLOv5RandomAffine scaling ratio\nlr_factor = 0.01  # Learning rate scaling factor\nweight_decay = 0.0005\n# Save model checkpoint and validation intervals\nsave_epoch_intervals = 1\n# The maximum checkpoints to keep.\nmax_keep_ckpts = 1\n# Single-scale training is recommended to\n# be turned on, which can speed up training.\nenv_cfg = dict(cudnn_benchmark=True)\n\n# ============================== Unmodified in most cases ===================\nmodel = dict(\n    type='YOLODetector',\n    data_preprocessor=dict(\n        type='YOLOv5DetDataPreprocessor',\n        mean=[0., 0., 0.],\n        std=[255., 255., 255.],\n        bgr_to_rgb=True),\n    backbone=dict(\n        type='YOLOv6EfficientRep',\n        out_indices=[1, 2, 3, 4],\n        use_cspsppf=True,\n        deepen_factor=deepen_factor,\n        widen_factor=widen_factor,\n        norm_cfg=dict(type='BN', momentum=0.03, eps=0.001),\n        act_cfg=dict(type='ReLU', inplace=True)),\n    neck=dict(\n        type='YOLOv6RepBiPAFPN',\n        deepen_factor=deepen_factor,\n        widen_factor=widen_factor,\n        in_channels=[128, 256, 512, 1024],\n        out_channels=[128, 256, 512],\n        num_csp_blocks=12,\n        norm_cfg=dict(type='BN', momentum=0.03, eps=0.001),\n        act_cfg=dict(type='ReLU', inplace=True),\n    ),\n    bbox_head=dict(\n        type='YOLOv6Head',\n        head_module=dict(\n            type='YOLOv6HeadModule',\n            num_classes=num_classes,\n            in_channels=[128, 256, 512],\n            widen_factor=widen_factor,\n            norm_cfg=dict(type='BN', momentum=0.03, eps=0.001),\n            act_cfg=dict(type='SiLU', inplace=True),\n            featmap_strides=[8, 16, 32]),\n        loss_bbox=dict(\n            type='IoULoss',\n            iou_mode='giou',\n            bbox_format='xyxy',\n            reduction='mean',\n            loss_weight=2.5,\n            return_iou=False)),\n    train_cfg=dict(\n        initial_epoch=4,\n        initial_assigner=dict(\n            type='BatchATSSAssigner',\n            num_classes=num_classes,\n            topk=9,\n            iou_calculator=dict(type='mmdet.BboxOverlaps2D')),\n        assigner=dict(\n            type='BatchTaskAlignedAssigner',\n            num_classes=num_classes,\n            topk=13,\n            alpha=1,\n            beta=6),\n    ),\n    test_cfg=dict(\n        multi_label=True,\n        nms_pre=30000,\n        score_thr=0.001,\n        nms=dict(type='nms', iou_threshold=0.65),\n        max_per_img=300))\n\n# The training pipeline of YOLOv6 is basically the same as YOLOv5.\n# The difference is that Mosaic and RandomAffine will be closed in the last 15 epochs. # noqa\npre_transform = [\n    dict(type='LoadImageFromFile', backend_args=_base_.backend_args),\n    dict(type='LoadAnnotations', with_bbox=True)\n]\n\ntrain_pipeline = [\n    *pre_transform,\n    dict(type='YOLOv5KeepRatioResize', scale=img_scale),\n    dict(\n        type='LetterResize',\n        scale=img_scale,\n        allow_scale_up=True,\n        pad_val=dict(img=114.0)),\n    dict(\n        type='mmdet.PackDetInputs',\n        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape'))\n]\n\ntrain_dataloader = dict(\n    batch_size=train_batch_size_per_gpu,\n    num_workers=train_num_workers,\n    collate_fn=dict(type='yolov5_collate'),\n    persistent_workers=persistent_workers,\n    pin_memory=True,\n    sampler=dict(type='DefaultSampler', shuffle=True),\n    dataset=dict(\n        type=dataset_type,\n        data_root=data_root,\n        metainfo=metainfo,\n        ann_file=train_ann_file,\n        data_prefix=dict(img=train_data_prefix),\n        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n        pipeline=train_pipeline))\n\ntest_pipeline = [\n    dict(type='LoadImageFromFile', backend_args=_base_.backend_args),\n    dict(type='YOLOv5KeepRatioResize', scale=img_scale),\n    dict(\n        type='LetterResize',\n        scale=img_scale,\n        allow_scale_up=True,\n        pad_val=dict(img=114.0)),\n    dict(type='LoadAnnotations', with_bbox=True, _scope_='mmdet'),\n    dict(\n        type='mmdet.PackDetInputs',\n        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n                   'scale_factor', 'pad_param'))\n]\n\nval_dataloader = dict(\n    batch_size=val_batch_size_per_gpu,\n    num_workers=val_num_workers,\n    persistent_workers=persistent_workers,\n    pin_memory=True,\n    drop_last=False,\n    sampler=dict(type='DefaultSampler', shuffle=False),\n    dataset=dict(\n        type=dataset_type,\n        data_root=data_root,\n        metainfo=metainfo,\n        test_mode=True,\n        data_prefix=dict(img=val_data_prefix),\n        ann_file=val_ann_file,\n        pipeline=test_pipeline,\n        batch_shapes_cfg=batch_shapes_cfg))\n\ntest_dataloader = val_dataloader\n\n# Optimizer and learning rate scheduler of YOLOv6 are basically the same as YOLOv5. # noqa\n# The difference is that the scheduler_type of YOLOv6 is cosine.\noptim_wrapper = dict(\n    type='OptimWrapper',\n    optimizer=dict(\n        type='SGD',\n        lr=base_lr,\n        momentum=0.937,\n        weight_decay=weight_decay,\n        nesterov=True,\n        batch_size_per_gpu=train_batch_size_per_gpu),\n    constructor='YOLOv5OptimizerConstructor')\n\ndefault_hooks = dict(\n    param_scheduler=dict(\n        type='YOLOv5ParamSchedulerHook',\n        scheduler_type='cosine',\n        lr_factor=lr_factor,\n        max_epochs=max_epochs),\n    logger=dict(type='LoggerHook', interval=5),\n    checkpoint=dict(\n        type='CheckpointHook',\n        interval=save_epoch_intervals,\n        max_keep_ckpts=max_keep_ckpts,\n        save_best='auto'))\n\nval_evaluator = dict(\n    type='mmdet.CocoMetric',\n    proposal_nums=(100, 1, 10),\n    classwise=True,\n    ann_file=data_root + val_ann_file,\n    metric='bbox')\ntest_evaluator = val_evaluator\n\ntrain_cfg = dict(\n    type='EpochBasedTrainLoop',\n    max_epochs=max_epochs,\n    val_interval=save_epoch_intervals)\nval_cfg = dict(type='ValLoop')\ntest_cfg = dict(type='TestLoop')\n\n\"\"\"\nwith open('/kaggle/working/mmyolo/configs/yolov6/yolov6_v3_s_syncbn_fast_8xb32-300e_coco.py', 'w') as f:\n    f.write(config_base_yolov6)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#for visualising the config\nfrom mmengine import Config\nimport json\ncfg = Config.fromfile('/kaggle/working/mmyolo/configs/yolov6/yolov6_v3_s_syncbn_fast_8xb32-300e_coco.py')\nformatted_cfg = json.dumps(cfg._cfg_dict, indent=4)\n\nprint(formatted_cfg)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# yolov6-m config","metadata":{}},{"cell_type":"code","source":"\nconfig_medium_yolov6 = \"\"\"\n\n_base_ = './yolov6_v3_s_syncbn_fast_8xb32-300e_coco.py'\n\n# ======================= Possible modified parameters =======================\n# -----model related-----\n# The scaling factor that controls the depth of the network structure\ndeepen_factor = 0.6\n# The scaling factor that controls the width of the network structure\nwiden_factor = 0.75\n\n# ============================== Unmodified in most cases =====================\nmodel = dict(\n    backbone=dict(\n        type='YOLOv6CSPBep',\n        deepen_factor=deepen_factor,\n        widen_factor=widen_factor,\n        hidden_ratio=2. / 3,\n        block_cfg=dict(type='RepVGGBlock'),\n        act_cfg=dict(type='ReLU', inplace=True)),\n    neck=dict(\n        type='YOLOv6CSPRepBiPAFPN',\n        deepen_factor=deepen_factor,\n        widen_factor=widen_factor,\n        block_cfg=dict(type='RepVGGBlock'),\n        hidden_ratio=2. / 3,\n        block_act_cfg=dict(type='ReLU', inplace=True)),\n    bbox_head=dict(\n        type='YOLOv6Head',\n        head_module=dict(reg_max=16, widen_factor=widen_factor)))\n        \n\"\"\"\nwith open('/kaggle/working/mmyolo/configs/yolov6/yolov6_v3_m_syncbn_fast_8xb32-300e_coco.py', 'w') as f:\n    f.write(config_medium_yolov6)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#for visualising the config\nfrom mmengine import Config\nimport json\ncfg = Config.fromfile('/kaggle/working/mmyolo/configs/yolov6/yolov6_v3_m_syncbn_fast_8xb32-300e_coco.py')\nformatted_cfg = json.dumps(cfg._cfg_dict, indent=4)\n\nprint(formatted_cfg)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# yolov6-l ","metadata":{}},{"cell_type":"code","source":"\nconfig_large_yolov6 = \"\"\"\n\n_base_ = './yolov6_v3_m_syncbn_fast_8xb32-300e_coco.py'\n\n# ======================= Possible modified parameters =======================\n# -----model related-----\n# The scaling factor that controls the depth of the network structure\ndeepen_factor = 1\n# The scaling factor that controls the width of the network structure\nwiden_factor = 1\n\n# ============================== Unmodified in most cases ===================\nmodel = dict(\n    backbone=dict(\n        deepen_factor=deepen_factor,\n        widen_factor=widen_factor,\n        hidden_ratio=1. / 2,\n        block_cfg=dict(\n            type='ConvWrapper',\n            norm_cfg=dict(type='BN', momentum=0.03, eps=0.001)),\n        act_cfg=dict(type='SiLU', inplace=True)),\n    neck=dict(\n        deepen_factor=deepen_factor,\n        widen_factor=widen_factor,\n        hidden_ratio=1. / 2,\n        block_cfg=dict(\n            type='ConvWrapper',\n            norm_cfg=dict(type='BN', momentum=0.03, eps=0.001)),\n        block_act_cfg=dict(type='SiLU', inplace=True)),\n    bbox_head=dict(head_module=dict(widen_factor=widen_factor)))\n\n\"\"\"\nwith open('/kaggle/working/mmyolo/configs/yolov6/yolov6_v3_l_syncbn_fast_8xb32-50e_pcb_defect.py', 'w') as f:\n    f.write(config_large_yolov6)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#for visualising the config\nfrom mmengine import Config\nimport json\ncfg = Config.fromfile('/kaggle/working/mmyolo/configs/yolov6/yolov6_v3_l_syncbn_fast_8xb32-50e_pcb_defect.py')\nformatted_cfg = json.dumps(cfg._cfg_dict, indent=4)\n\nprint(formatted_cfg)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# saving the config file\nfrom mmengine import Config\nimport json\n\n# Load the configuration from file\ncfg = Config.fromfile('/kaggle/working/mmyolo/configs/yolov6/yolov6_v3_l_syncbn_fast_8xb32-50e_pcb_defect.py')\n\n# Convert the configuration to a dictionary and then to a formatted JSON string\nformatted_cfg = json.dumps(cfg._cfg_dict, indent=4)\n\n# Define the output file path\noutput_file = '/kaggle/working/formatted_config.json'\n\n# Save the formatted JSON string to a file\nwith open(output_file, 'w') as f:\n    f.write(formatted_cfg)\n\nprint(f'Configuration saved as {output_file}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualizing the dataset ","metadata":{}},{"cell_type":"code","source":"# !python tools/analysis_tools/browse_dataset.py configs/yolov6/yolov6_v3_l_syncbn_fast_8xb32-50e_pcb_defect.py --phase train --mode pipeline --out-dir dataset_check_8 --show-number 8 --show-interval 10","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training model","metadata":{}},{"cell_type":"code","source":"!bash ./tools/dist_train.sh configs/yolov6/yolov6_v3_l_syncbn_fast_8xb32-50e_pcb_defect.py 2 --work-dir yolov6_loserspcb_50e/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Saving the weight file","metadata":{}},{"cell_type":"code","source":"# Just to look at the converted data\n\nimport shutil\n\n# Directory to be zipped\ndirectory_to_zip = '/kaggle/working/mmyolo/yolov6_loserspcb_50e'\n\n# Destination zip file path\nzip_file_path = '/kaggle/working/yolov6_loserspcb_50e'\n\n# Create a zip file\nshutil.make_archive(zip_file_path[:-4], 'zip', directory_to_zip)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing the model","metadata":{}},{"cell_type":"code","source":"# !python tools/test.py \\\n# configs/yolov8/yolov8_m_syncbn_fast_8xb16-50e_pcb_defect.py \\\n# /kaggle/input/inference/best_coco_bbox_mAP_epoch_25.pth\\\n# --work-dir results/evaluate \\\n# --out results/results.pkl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# FLOPS ","metadata":{}},{"cell_type":"code","source":"# !python tools/analysis_tools/get_flops.py configs/yolov8/yolov8_m_syncbn_fast_8xb16-50e_pcb_defect.py --shape 640 640","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Benchmark","metadata":{}},{"cell_type":"code","source":"# !python tools/analysis_tools/benchmark.py configs/yolov8/yolov8_m_syncbn_fast_8xb16-50e_pcb_defect.py \\\n# /kaggle/input/inference/best_coco_bbox_mAP_epoch_25.pth \\\n# --repeat-num 5 \\\n# --max-iter 200 \\\n# --log-interval 50 \\\n# --work-dir ./results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# code ='''\n\n# import argparse\n# import os\n# import csv\n# import matplotlib.pyplot as plt\n# import numpy as np\n# from matplotlib.ticker import MultipleLocator\n# from mmcv.ops import nms\n# from mmengine import Config, DictAction\n# from mmengine.fileio import load\n# from mmengine.registry import init_default_scope\n# from mmengine.utils import ProgressBar\n\n# from mmdet.evaluation import bbox_overlaps\n# from mmdet.registry import DATASETS\n# from mmdet.utils import replace_cfg_vals, update_data_root\n\n\n# def parse_args():\n#     parser = argparse.ArgumentParser(\n#         description='Generate confusion matrix from detection results')\n#     parser.add_argument('config', help='test config file path')\n#     parser.add_argument(\n#         'prediction_path', help='prediction path where test .pkl result')\n#     parser.add_argument(\n#         'save_dir', help='directory where confusion matrix will be saved')\n#     parser.add_argument(\n#         '--show', action='store_true', help='show confusion matrix')\n#     parser.add_argument(\n#         '--color-theme',\n#         default='plasma',\n#         help='theme of the matrix color map')\n#     parser.add_argument(\n#         '--score-thr',\n#         type=float,\n#         default=0.3,\n#         help='score threshold to filter detection bboxes')\n#     parser.add_argument(\n#         '--tp-iou-thr',\n#         type=float,\n#         default=0.5,\n#         help='IoU threshold to be considered as matched')\n#     parser.add_argument(\n#         '--nms-iou-thr',\n#         type=float,\n#         default=None,\n#         help='nms IoU threshold, only applied when users want to change the'\n#         'nms IoU threshold.')\n#     parser.add_argument(\n#         '--cfg-options',\n#         nargs='+',\n#         action=DictAction,\n#         help='override some settings in the used config, the key-value pair '\n#         'in xxx=yyy format will be merged into config file. If the value to '\n#         'be overwritten is a list, it should be like key=\"[a,b]\" or key=a,b '\n#         'It also allows nested list/tuple values, e.g. key=\"[(a,b),(c,d)]\" '\n#         'Note that the quotation marks are necessary and that no white space '\n#         'is allowed.')\n#     args = parser.parse_args()\n#     return args\n\n\n# def calculate_confusion_matrix(dataset,\n#                                results,\n#                                score_thr=0,\n#                                nms_iou_thr=None,\n#                                tp_iou_thr=0.5):\n#     \"\"\"Calculate the confusion matrix.\n\n#     Args:\n#         dataset (Dataset): Test or val dataset.\n#         results (list[ndarray]): A list of detection results in each image.\n#         score_thr (float|optional): Score threshold to filter bboxes.\n#             Default: 0.\n#         nms_iou_thr (float|optional): nms IoU threshold, the detection results\n#             have done nms in the detector, only applied when users want to\n#             change the nms IoU threshold. Default: None.\n#         tp_iou_thr (float|optional): IoU threshold to be considered as matched.\n#             Default: 0.5.\n#     \"\"\"\n#     num_classes = len(dataset.metainfo['classes'])\n#     confusion_matrix = np.zeros(shape=[num_classes + 1, num_classes + 1])\n#     assert len(dataset) == len(results)\n#     prog_bar = ProgressBar(len(results))\n#     for idx, per_img_res in enumerate(results):\n#         res_bboxes = per_img_res['pred_instances']\n#         gts = dataset.get_data_info(idx)['instances']\n#         analyze_per_img_dets(confusion_matrix, gts, res_bboxes, score_thr,\n#                              tp_iou_thr, nms_iou_thr)\n#         prog_bar.update()\n#     return confusion_matrix\n\n\n# def analyze_per_img_dets(confusion_matrix,\n#                          gts,\n#                          result,\n#                          score_thr=0,\n#                          tp_iou_thr=0.5,\n#                          nms_iou_thr=None):\n#     \"\"\"Analyze detection results on each image.\n\n#     Args:\n#         confusion_matrix (ndarray): The confusion matrix,\n#             has shape (num_classes + 1, num_classes + 1).\n#         gt_bboxes (ndarray): Ground truth bboxes, has shape (num_gt, 4).\n#         gt_labels (ndarray): Ground truth labels, has shape (num_gt).\n#         result (ndarray): Detection results, has shape\n#             (num_classes, num_bboxes, 5).\n#         score_thr (float): Score threshold to filter bboxes.\n#             Default: 0.\n#         tp_iou_thr (float): IoU threshold to be considered as matched.\n#             Default: 0.5.\n#         nms_iou_thr (float|optional): nms IoU threshold, the detection results\n#             have done nms in the detector, only applied when users want to\n#             change the nms IoU threshold. Default: None.\n#     \"\"\"\n#     true_positives = np.zeros(len(gts))\n#     gt_bboxes = []\n#     gt_labels = []\n#     for gt in gts:\n#         gt_bboxes.append(gt['bbox'])\n#         gt_labels.append(gt['bbox_label'])\n\n#     gt_bboxes = np.array(gt_bboxes)\n#     gt_labels = np.array(gt_labels)\n\n#     unique_label = np.unique(result['labels'].numpy())\n\n#     for det_label in unique_label:\n#         mask = (result['labels'] == det_label)\n#         det_bboxes = result['bboxes'][mask].numpy()\n#         det_scores = result['scores'][mask].numpy()\n\n#         if nms_iou_thr:\n#             det_bboxes, _ = nms(\n#                 det_bboxes, det_scores, nms_iou_thr, score_threshold=score_thr)\n#         ious = bbox_overlaps(det_bboxes[:, :4], gt_bboxes)\n#         for i, score in enumerate(det_scores):\n#             det_match = 0\n#             if score >= score_thr:\n#                 for j, gt_label in enumerate(gt_labels):\n#                     if ious[i, j] >= tp_iou_thr:\n#                         det_match += 1\n#                         if gt_label == det_label:\n#                             true_positives[j] += 1  # TP\n#                         confusion_matrix[gt_label, det_label] += 1\n#                 if det_match == 0:  # BG FP\n#                     confusion_matrix[-1, det_label] += 1\n#     for num_tp, gt_label in zip(true_positives, gt_labels):\n#         if num_tp == 0:  # FN\n#             confusion_matrix[gt_label, -1] += 1\n\n\n# def save_confusion_matrix(confusion_matrix, labels, save_dir):\n#     \"\"\"Save confusion matrix to a CSV file.\n\n#     Args:\n#         confusion_matrix (ndarray): The confusion matrix.\n#         labels (list[str]): List of class names.\n#         save_dir (str): Directory where the confusion matrix will be saved.\n#     \"\"\"\n#     save_path = os.path.join(save_dir, 'confusion_matrix.csv')\n#     with open(save_path, 'w', newline='') as csvfile:\n#         csvwriter = csv.writer(csvfile)\n#         csvwriter.writerow([''] + labels + ['background'])\n#         for i, row in enumerate(confusion_matrix):\n#             csvwriter.writerow([labels[i] if i < len(labels) else 'background'] + row.tolist())\n\n\n# def plot_confusion_matrix(confusion_matrix,\n#                           labels,\n#                           save_dir=None,\n#                           show=True,\n#                           title='Normalized Confusion Matrix',\n#                           color_theme='plasma'):\n#     \"\"\"Draw confusion matrix with matplotlib.\n\n#     Args:\n#         confusion_matrix (ndarray): The confusion matrix.\n#         labels (list[str]): List of class names.\n#         save_dir (str|optional): If set, save the confusion matrix plot to the\n#             given path. Default: None.\n#         show (bool): Whether to show the plot. Default: True.\n#         title (str): Title of the plot. Default: `Normalized Confusion Matrix`.\n#         color_theme (str): Theme of the matrix color map. Default: `plasma`.\n#     \"\"\"\n#     # normalize the confusion matrix\n#     per_label_sums = confusion_matrix.sum(axis=1)[:, np.newaxis]\n#     confusion_matrix = \\\n#         confusion_matrix.astype(np.float32) / per_label_sums * 100\n\n#     num_classes = len(labels)\n#     fig, ax = plt.subplots(\n#         figsize=(0.5 * num_classes, 0.5 * num_classes * 0.8), dpi=180)\n#     cmap = plt.get_cmap(color_theme)\n#     im = ax.imshow(confusion_matrix, cmap=cmap)\n#     plt.colorbar(mappable=im, ax=ax)\n\n#     title_font = {'weight': 'bold', 'size': 12}\n#     ax.set_title(title, fontdict=title_font)\n#     label_font = {'size': 10}\n#     plt.ylabel('Ground Truth Label', fontdict=label_font)\n#     plt.xlabel('Prediction Label', fontdict=label_font)\n\n#     # draw locator\n#     xmajor_locator = MultipleLocator(1)\n#     xminor_locator = MultipleLocator(0.5)\n#     ax.xaxis.set_major_locator(xmajor_locator)\n#     ax.xaxis.set_minor_locator(xminor_locator)\n#     ymajor_locator = MultipleLocator(1)\n#     yminor_locator = MultipleLocator(0.5)\n#     ax.yaxis.set_major_locator(ymajor_locator)\n#     ax.yaxis.set_minor_locator(yminor_locator)\n\n#     # draw grid\n#     ax.grid(True, which='minor', linestyle='-')\n\n#     # draw label\n#     ax.set_xticks(np.arange(num_classes))\n#     ax.set_yticks(np.arange(num_classes))\n#     ax.set_xticklabels(labels)\n#     ax.set_yticklabels(labels)\n\n#     ax.tick_params(\n#         axis='x', bottom=False, top=True, labelbottom=False, labeltop=True)\n#     plt.setp(\n#         ax.get_xticklabels(), rotation=45, ha='left', rotation_mode='anchor')\n\n#     # draw confution matrix value\n#     for i in range(num_classes):\n#         for j in range(num_classes):\n#             ax.text(\n#                 j,\n#                 i,\n#                 '{}%'.format(\n#                     int(confusion_matrix[\n#                         i,\n#                         j]) if not np.isnan(confusion_matrix[i, j]) else -1),\n#                 ha='center',\n#                 va='center',\n#                 color='w',\n#                 size=7)\n\n#     ax.set_ylim(len(confusion_matrix) - 0.5, -0.5)  # matplotlib>3.1.1\n\n#     fig.tight_layout()\n#     if save_dir is not None:\n#         plt.savefig(\n#             os.path.join(save_dir, 'confusion_matrix.png'), format='png')\n#     if show:\n#         plt.show()\n\n\n# def main():\n#     args = parse_args()\n\n#     cfg = Config.fromfile(args.config)\n\n#     # replace the ${key} with the value of cfg.key\n#     cfg = replace_cfg_vals(cfg)\n\n#     # update data root according to MMDET_DATASETS\n#     update_data_root(cfg)\n\n#     if args.cfg_options is not None:\n#         cfg.merge_from_dict(args.cfg_options)\n\n#     init_default_scope(cfg.get('default_scope', 'mmdet'))\n\n#     results = load(args.prediction_path)\n\n#     if not os.path.exists(args.save_dir):\n#         os.makedirs(args.save_dir)\n\n#     dataset = DATASETS.build(cfg.test_dataloader.dataset)\n\n#     confusion_matrix = calculate_confusion_matrix(dataset, results,\n#                                                   args.score_thr,\n#                                                   args.nms_iou_thr,\n#                                                   args.tp_iou_thr)\n#     class_labels = list(dataset.metainfo['classes']) + ['background']\n#     save_confusion_matrix(confusion_matrix, class_labels, args.save_dir)\n#     plot_confusion_matrix(\n#         confusion_matrix,\n#         class_labels,\n#         save_dir=args.save_dir,\n#         show=args.show,\n#         color_theme=args.color_theme)\n\n\n# if __name__ == '__main__':\n#     main()\n# '''\n\n# with open('./tools/analysis_tools/confusion_matrix_2.py', 'w') as f:\n#     f.write(code)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !python tools/analysis_tools/confusion_matrix_2.py \\\n# configs/yolov8/yolov8_m_syncbn_fast_8xb16-50e_pcb_defect.py  \\\n# results/results.pkl  \\\n# ./results \\\n# --show \\\n# --score-thr 0.5 \\\n# --tp-iou-thr 0.5","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Saving the Results","metadata":{}},{"cell_type":"code","source":"# import shutil\n\n# # Directory to be zipped\n# directory_to_zip = '/kaggle/working/mmyolo/results'\n\n# # Destination zip file path\n# zip_file_path = '/kaggle/working/yolov8_dspcbsd_results.zip'\n\n# # Create a zip file\n# shutil.make_archive(zip_file_path[:-4], 'zip', directory_to_zip)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# from mmdet.apis import init_detector, inference_detector\n\n# config = 'configs/yolov8/yolov8_m_syncbn_fast_8xb16-50e_pcb_defect.py'\n# checkpoint = '/kaggle/input/inference/best_coco_bbox_mAP_epoch_25.pth'\n\n# model = init_detector(config, checkpoint, device='cuda:0')  # 'cpu' or device='cuda:0'\n\n# img = '/kaggle/input/dspcbsd/Data_COCO/val/0066079.jpg'\n\n# result = inference_detector(model, img)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from mmdet.apis import DetInferencer\n# import glob\n\n# # Choose to use a config\n# config = '/content/mmdetection/configs/atss/atss_r50_fpn_1x_raccoon.py'\n\n# # Setup a checkpoint file to load from work_dirs folder\n# checkpoint = glob.glob('/content/mmdetection/work_dirs/atss_r50_fpn_1x_raccoon/best_coco_bbox_mAP_epoch_1.pth')[0]\n\n# # Set the device to be used for evaluation\n# device = 'cuda:0'\n\n# # Initialize the DetInferencer\n# inferencer = DetInferencer(config, checkpoint, device)\n\n# # Use the detector to do inference\n# img = '/content/mmdetection/Raccoons-2/test/raccoon-66_jpg.rf.f0160e8a2f9a23455b0394df3607859f.jpg'\n# result = inferencer(img, out_dir='./output')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}